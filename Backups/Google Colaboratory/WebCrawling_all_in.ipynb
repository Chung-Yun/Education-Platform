{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WebCrawling_all_in.ipynb","provenance":[],"authorship_tag":"ABX9TyPZy+5KCoSJjEE71v3AomIA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"AzeHusfcuXLC"},"source":["# MIT License\n","\n","# Copyright (c) 2020 Colleabois, yung-chun\n","\n","# Permission is hereby granted, free of charge, to any person obtaining a copy\n","# of this software and associated documentation files (the \"Software\"), to deal\n","# in the Software without restriction, including without limitation the rights\n","# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","# copies of the Software, and to permit persons to whom the Software is\n","# furnished to do so, subject to the following conditions:\n","\n","# The above copyright notice and this permission notice shall be included in all\n","# copies or substantial portions of the Software.\n","\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","# SOFTWARE."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDZKUVAjZujR"},"source":["from IPython import display # Some of the output are just too long and too ugly so need this to adjust the display \n","!pip install -q gwpy # To omit output, add \"%%capture\" in the beginning of the cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMkIjBKzZ0zm"},"source":["%%capture \n","!pip install selenium\n","!apt-get update # to update ubuntu to correctly run apt install\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWo9ON1SZ5WA","executionInfo":{"status":"ok","timestamp":1608159311707,"user_tz":-60,"elapsed":12017,"user":{"displayName":"Jui-Ting LU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNjK4Nv1boLTdy8uRQSl8bZBcN6ZiC7-2iuWrx=s64","userId":"05041109725365710945"}},"outputId":"25f022ee-0e73-4dbb-db8c-f0169f683be2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bfp5rDtpaH6N"},"source":["import requests\n","from bs4 import BeautifulSoup\n","import time\n","from selenium import webdriver\n","from selenium.webdriver import ActionChains\n","import pandas as pd \n","import datetime\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","chromedriver_path = 'chromedriver' # for GD"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtaKVWlfY-TM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608160267851,"user_tz":-60,"elapsed":968144,"user":{"displayName":"Jui-Ting LU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNjK4Nv1boLTdy8uRQSl8bZBcN6ZiC7-2iuWrx=s64","userId":"05041109725365710945"}},"outputId":"4d9544b7-eb16-4ea5-f1d0-71fe8cb43a26"},"source":["# initialise dataframe\n","# df = pd.DataFrame({'圖片':[],'價格':[],'講師':[],\"標題\":[], \"url\": [], \"星數\" : [], \"日期\" : [], \"評論標題\" : [], \"評論內文\" : []})\n","df = pd.DataFrame({\\\n","\"class_title\"   : [], \\\n","\"class_url\"     : [], \\\n","\"class_figure\"  : [], \\\n","\"stars\"         : [], \\\n","\"teacher_name\"  : [], \\\n","\"price\"         : [], \\\n","\"comment_date\"  : [], \\\n","\"comment_title\" : [], \\\n","\"comment_text\"  : []}) \n","\n","target = 'python'\n","first_url = 'https://hahow.in/courses?search='+target\n","\n","# Define total page\n","def findTotalPage(myurl):\n","    first_driver = webdriver.Chrome(chromedriver_path, options=chrome_options)\n","    first_page = first_driver.get(myurl)\n","    time.sleep(3) \n","    first_soup = BeautifulSoup(first_driver.page_source, 'html.parser')\n","    page_block = first_soup.find_all('ul',{'class':\"rc-pagination gbga9a-0 jYLVph\"})\n","    assert len(page_block)==1\n","    pages_plus_arrows = page_block[0].find_all('li') # 這邊會多算兩個箭頭\n","    first_driver.quit()\n","    return len(pages_plus_arrows) - 2\n","total_page = findTotalPage(first_url)\n","\n","page = 0\n","n_class = 0\n","while (page < total_page ):\n","    page += 1\n","    url = 'https://hahow.in/courses?search=python&page='+str(page)\n","    mydriver0 = webdriver.Chrome(chromedriver_path , options=chrome_options)\n","    gettingurl0 = mydriver0.get(url)  #\n","    print(\"資料爬起來! >>> 第\"+str(page)+\"/\"+str(total_page)+\"頁：\")\n","    time.sleep(3)\n","    source = mydriver0.page_source\n","    soup = BeautifulSoup(source, 'html.parser')\n","    class_block = soup.find_all('div',{'class':'sc-10r5mg2-0 fVNHJD hh-course-brief relative block '})  # 在ＧＤ上跑，最後面需要空格（我不知道為什麼）\n","    for class_ in class_block :\n","        n_class+=1\n","        class_href = class_.find('div','cover-wrap relative').find('a')\n","        class_url ='https://hahow.in'+ class_href.get('href')\n","        mydriver1 = webdriver.Chrome(chromedriver_path , options=chrome_options)\n","        gettingurl1 = mydriver1.get(class_url)\n","        time.sleep(3)\n","        response_source = mydriver1.page_source\n","        response_soup = BeautifulSoup(response_source, 'html.parser')  \n","        title = response_soup.find('h1').text\n","        if 'Python' in title : # 有符合條件才找\n","            img = response_soup.find('div',class_='plyr__video-wrapper').find('video')\n","            # img_url\n","            img_url = img.get('poster')\n","            # price\n","            if response_soup.find('h4',class_='marg-tb-0')  == None and response_soup.find('h1',class_='price') == None :\n","                price = response_soup.find('h2').text\n","            elif response_soup.find('div',class_='text-sm marg-tb-0') == None and response_soup.find('div',class_='proposal-pricing') == None :\n","                price = response_soup.find('h1',class_='price').text\n","            else:\n","                price = response_soup.find('h4',class_='marg-tb-0').text      \n","            # teacher_name  \n","            teacher_data = response_soup.find_all('div',class_='sc-1l1teqs-0 iFCjAI')\n","            for teacher in teacher_data:\n","                teacher_list = teacher.text\n","                if '老師' in teacher_list :\n","                    teacher_name = teacher_list[5:]\n","\n","            url_feedback = class_url +'/feedbacks'\n","            mydriver2 = webdriver.Chrome('chromedriver', options=chrome_options)\n","            gettingurl2 = mydriver2.get(url_feedback)\n","            time.sleep(3)\n","\n","            haveButton = True\n","            n_press = 0\n","            while haveButton == True:\n","                try: # when there is the continue button\n","                    actions = ActionChains(mydriver2)\n","                    seeMoreButton = mydriver2.find_elements_by_xpath(\"//button[@class='sc-1a6j6ze-0 cYdxxq b21euj-2 gMMXlv']\")[0] # 看更多\n","                    actions.click(seeMoreButton)\n","                    n_press+=1\n","                    actions.perform()\n","                    time.sleep(3)\n","                except:\n","                    haveButton = False \n","            # After pressing button 'n_press' times ...\n","            source2 =  mydriver2.page_source\n","            soup2 = BeautifulSoup(source2, 'html.parser')            \n","            comments = soup2.find_all('div',{'class':'wei2cc-1 gUylJK marg-b-25'})\n","            count = 0 # reinitialize nc\n","            stars = []; dates = []; shortTitles = []; longComments = []\n","            for comment in comments:\n","                count+=1\n","                starRating = comment.find('p',{'class':'marg-b-0'})\n","                rating = comment.find('div',{'class':'star-ratings'})\n","                star = rating.attrs['title']\n","                date = comment.find('time').text\n","                shortTitle = comment.find('p',{'class':'text-strong marg-b-5'}).text\n","                longComment = comment.find('p',class_='marg-b-0').text\n","                stars.append(star)\n","                dates.append(date)\n","                shortTitles.append(shortTitle)\n","                longComments.append(longComment)\n","            if count!=0: # 如果有搜到評論 \n","                df_of_1_course = pd.DataFrame({\\\n","                                   \"class_title\"   : title, \\\n","                                   \"class_url\"     : class_url, \\\n","                                   \"class_figure\"  : img_url, \\\n","                                   \"stars\"         : stars, \\\n","                                   \"teacher_name\"  : teacher_name, \\\n","                                   \"price\"         : price, \\\n","                                   \"comment_date\"  : dates, \\\n","                                   \"comment_title\" : shortTitles, \\\n","                                   \"comment_text\"  : longComments}) \n","                # update the dataframe\n","                df = df.append(df_of_1_course, ignore_index = True) \n","            print('---第'+str(n_class)+'筆------按了'+str(n_press)+'次------收錄'+ str(count)+ '個評論-----------') \n","            mydriver2.quit() \n","        else:\n","            print('---第'+str(n_class)+'筆-----課程名稱沒有'+target)\n","        mydriver1.quit() \n","    mydriver0.quit()\n","\n","\n","# save file (in Google Drive)\n","current_date = datetime.datetime.today().strftime ('%d-%b-%Y')\n","# change the path when neccesary\n","df.to_csv(r'/content/gdrive/My Drive/ccClub-教育平台專案/output/'+str(page)+'page_result_'+str(current_date)+'.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["資料爬起來! >>> 第1/2頁：\n","---第1筆------按了0次------收錄0個評論-----------\n","---第2筆------按了0次------收錄0個評論-----------\n","---第3筆------按了0次------收錄0個評論-----------\n","---第4筆------按了0次------收錄0個評論-----------\n","---第5筆------按了0次------收錄5個評論-----------\n","---第6筆------按了0次------收錄7個評論-----------\n","---第7筆------按了0次------收錄12個評論-----------\n","---第8筆------按了0次------收錄12個評論-----------\n","---第9筆------按了0次------收錄0個評論-----------\n","---第10筆------按了0次------收錄5個評論-----------\n","---第11筆------按了1次------收錄25個評論-----------\n","---第12筆------按了6次------收錄125個評論-----------\n","---第13筆------按了5次------收錄116個評論-----------\n","---第14筆------按了0次------收錄9個評論-----------\n","---第15筆------按了29次------收錄588個評論-----------\n","---第16筆------按了7次------收錄150個評論-----------\n","---第17筆------按了3次------收錄68個評論-----------\n","---第18筆------按了4次------收錄87個評論-----------\n","---第19筆-----課程名稱沒有python\n","---第20筆-----課程名稱沒有python\n","---第21筆-----課程名稱沒有python\n","---第22筆-----課程名稱沒有python\n","---第23筆-----課程名稱沒有python\n","---第24筆-----課程名稱沒有python\n","資料爬起來! >>> 第2/2頁：\n","---第25筆-----課程名稱沒有python\n","---第26筆-----課程名稱沒有python\n","---第27筆-----課程名稱沒有python\n","---第28筆-----課程名稱沒有python\n","---第29筆-----課程名稱沒有python\n","---第30筆-----課程名稱沒有python\n","---第31筆-----課程名稱沒有python\n","---第32筆-----課程名稱沒有python\n","---第33筆-----課程名稱沒有python\n","---第34筆-----課程名稱沒有python\n","---第35筆-----課程名稱沒有python\n","---第36筆-----課程名稱沒有python\n","---第37筆-----課程名稱沒有python\n","---第38筆-----課程名稱沒有python\n","---第39筆-----課程名稱沒有python\n","---第40筆-----課程名稱沒有python\n"],"name":"stdout"}]}]}